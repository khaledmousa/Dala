// Signature file for parser generated by fsyacc
module DalaParser
type token = 
  | EOF
  | LET
  | BEGINSCOPE
  | ENDSCOPE
  | OPENBRACKET
  | CLOSINGBRACKET
  | ENDSTATEMENT
  | IF
  | RETURN
  | PLUS
  | MINUS
  | MULT
  | DIV
  | ASSIGN
  | EQ
  | NE
  | LT
  | GT
  | LTE
  | GTE
  | INT of (int)
  | ID of (string)
type tokenId = 
    | TOKEN_EOF
    | TOKEN_LET
    | TOKEN_BEGINSCOPE
    | TOKEN_ENDSCOPE
    | TOKEN_OPENBRACKET
    | TOKEN_CLOSINGBRACKET
    | TOKEN_ENDSTATEMENT
    | TOKEN_IF
    | TOKEN_RETURN
    | TOKEN_PLUS
    | TOKEN_MINUS
    | TOKEN_MULT
    | TOKEN_DIV
    | TOKEN_ASSIGN
    | TOKEN_EQ
    | TOKEN_NE
    | TOKEN_LT
    | TOKEN_GT
    | TOKEN_LTE
    | TOKEN_GTE
    | TOKEN_INT
    | TOKEN_ID
    | TOKEN_end_of_input
    | TOKEN_error
type nonTerminalId = 
    | NONTERM__startstart
    | NONTERM_start
    | NONTERM_statement_list
    | NONTERM_statement
    | NONTERM_expression
    | NONTERM_op
/// This function maps tokens to integer indexes
val tagOfToken: token -> int

/// This function maps integer indexes to symbolic token ids
val tokenTagToTokenId: int -> tokenId

/// This function maps production indexes returned in syntax errors to strings representing the non terminal that would be produced by that production
val prodIdxToNonTerminal: int -> nonTerminalId

/// This function gets the name of a token as a string
val token_to_string: token -> string
val start : (Microsoft.FSharp.Text.Lexing.LexBuffer<'cty> -> token) -> Microsoft.FSharp.Text.Lexing.LexBuffer<'cty> -> (Dala.stmt) 
